{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "001906d4-6d8d-4d0e-9b75-22ad5391758e",
   "metadata": {},
   "source": [
    "# Capstone 4: Pre-processing And Modeling\n",
    "### By Joshua Dytko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c658d1-230d-47f5-90a8-f19979fcdebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# While there is a custom built train test split function that function still uses the sklearn train_test_split function within it \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Surpise imports\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise import accuracy\n",
    "from surprise import KNNBasic\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Evaluate RMSE\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d920c-a809-4033-99d4-977f861ac969",
   "metadata": {},
   "source": [
    "I will build three user based collaborative filtering models. The models that will be used are K-Nearest Neighbors (KNN) and Singular Value Decomposition (SVD) from the Surprise library and Alternating Least Squares (ALS) from PySpark. Surprise is a library for building item recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6020e4-0c51-4db6-866a-8bd12717b756",
   "metadata": {},
   "source": [
    "Surprise has it's own train test split function, but that function does not guarantee that all products and user's are represented in both training and test splits. The model is going to be a collaborative filtering model. It will need every product and user present in both sets for it to be able to make useful predictions because the data is not available to handle the cold start problem. The customer train test split will do exactly that using the train test split from sklearn on user groups generated from pandas groupby functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef624c22-d6a4-4f5b-a56b-73d400da36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train test splits that contain all items and users\n",
    "def custom_train_test_split(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the DataFrame into training and test sets such that every user and item\n",
    "    appears in both sets.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame with columns ['user_id', 'asin', 'rating']\n",
    "    - test_size: float between 0.0 and 1.0, represents the proportion of the dataset to include in the test split\n",
    "\n",
    "    Returns:\n",
    "    - train_df: Training DataFrame\n",
    "    - test_df: Test DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    train_list = []\n",
    "    test_list = []\n",
    "\n",
    "    # Group by user_id\n",
    "    user_group = df.groupby('user_id')\n",
    "\n",
    "    for user_id, group in user_group:\n",
    "        if len(group) >= 2:\n",
    "            # If the user has more than one interaction, split their data\n",
    "            train, test = train_test_split(group, test_size=test_size, random_state=random_state)\n",
    "            train_list.append(train)\n",
    "            test_list.append(test)\n",
    "        else:\n",
    "            # If the user has only one interaction, include it in both train and test sets\n",
    "            train_list.append(group)\n",
    "            test_list.append(group)\n",
    "\n",
    "    # Concatenate all user splits\n",
    "    train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "    test_df = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "    # Ensure all items are in both sets\n",
    "    # Find items not in train_df\n",
    "    missing_items_in_train = set(df['asin'].unique()) - set(train_df['asin'].unique())\n",
    "    # Add missing items to train_df\n",
    "    if missing_items_in_train:\n",
    "        items_to_add = df[df['asin'].isin(missing_items_in_train)]\n",
    "        train_df = pd.concat([train_df, items_to_add]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Repeat for test_df\n",
    "    missing_items_in_test = set(df['asin'].unique()) - set(test_df['asin'].unique())\n",
    "    if missing_items_in_test:\n",
    "        items_to_add = df[df['asin'].isin(missing_items_in_test)]\n",
    "        test_df = pd.concat([test_df, items_to_add]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Remove any duplicates that might have been introduced from the previous 2 steps\n",
    "    train_df = train_df.drop_duplicates(subset=['user_id', 'asin', 'rating'])\n",
    "    test_df = test_df.drop_duplicates(subset=['user_id', 'asin', 'rating'])\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5333aef-4019-4886-a531-91e2aa83f549",
   "metadata": {},
   "source": [
    "Here will be the top-N and the compute precision and recall at k functions as well as the relevance threshold, which will be set to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977c06f3-f3c4-4db2-be5e-de5499e62b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevance threshold (e.g., ratings >= 4)\n",
    "relevance_threshold = 4.0\n",
    "\n",
    "# Return the top-N recommendation for each user from a set of predictions\n",
    "def get_top_n(predictions, n=10):\n",
    "    # Map the predictions to each user\n",
    "    top_n = defaultdict(list)\n",
    "    for pred in predictions:\n",
    "        user_id = pred.uid\n",
    "        item_id = pred.iid\n",
    "        est = pred.est\n",
    "        top_n[user_id].append((item_id, est))\n",
    "    \n",
    "    # Sort the predictions for each user and retrieve the top n\n",
    "    for user_id, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[user_id] = user_ratings[:n]\n",
    "    \n",
    "    return top_n\n",
    "    \n",
    "# Compute Precision@K and Recall@K for each user\n",
    "def compute_precision_recall_at_k(top_n, actual_ratings, k=10, threshold=4.0):\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    \n",
    "    for user_id, user_predictions in top_n.items():\n",
    "        # Get the set of recommended items\n",
    "        recommended_items = set([item_id for (item_id, _) in user_predictions[:k]])\n",
    "        \n",
    "        # Get the set of relevant items from actual ratings\n",
    "        relevant_items = set(actual_ratings[user_id])\n",
    "        \n",
    "        # Compute precision and recall\n",
    "        n_relevant_and_recommended = len(recommended_items & relevant_items)\n",
    "        precisions[user_id] = n_relevant_and_recommended / k\n",
    "        recalls[user_id] = n_relevant_and_recommended / len(relevant_items) if relevant_items else 0.0\n",
    "    \n",
    "    # Compute average precision and recall\n",
    "    average_precision = sum(precisions.values()) / len(precisions)\n",
    "    average_recall = sum(recalls.values()) / len(recalls)\n",
    "    \n",
    "    return average_precision, average_recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9e2e5-b7f4-4033-a196-9d78befc1f2d",
   "metadata": {},
   "source": [
    "Reading in the cleaned data created in the previous step in the capstone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50949b25-ef4b-41e5-bf2a-1a3e9740cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned data.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b240810-c29f-4794-8b02-56389f1cc65d",
   "metadata": {},
   "source": [
    "Confirmed the data types that are read in are what are expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8482910c-e62d-49b4-a6cb-9414f9f14bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating      int64\n",
       "user_id    object\n",
       "asin       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed86a90-9e27-4f93-a4fb-fef1ba4bca65",
   "metadata": {},
   "source": [
    "I found that ALS did failed if rating was not set to a float data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b733cdf-33a3-437d-8c83-506dbce706bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = df['rating'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c2074c-136e-4d7c-8407-777c9f24a084",
   "metadata": {},
   "source": [
    "Create the train and test split using the custom train test split function. The random state is set to 42 to generate repeatable resutls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d35293-4c38-45a3-9dd8-f2320ba801d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "train_df, test_df = custom_train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reset index\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffbea70-bc54-461e-89e5-292b818589d2",
   "metadata": {},
   "source": [
    "Before I was using surprise I tried using sparse matrices. For that I mapped the user ids and asin to mapped ids. Surprise does not need the data mapped but ALS requires the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4cc16d2-9dcc-4514-9469-881533b42823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings\n",
    "user_id_mapping = {id: idx for idx, id in enumerate(df['user_id'].unique())}\n",
    "item_id_mapping = {id: idx for idx, id in enumerate(df['asin'].unique())}\n",
    "\n",
    "# Reverse mappings - Wiill be used for the ALS PySpark model\n",
    "user_index_to_id = {idx: id for id, idx in user_id_mapping.items()}\n",
    "item_index_to_id = {idx: id for id, idx in item_id_mapping.items()}\n",
    "\n",
    "# Add mapped indices to dataframes\n",
    "for dataset in [train_df, test_df]:\n",
    "    dataset['user_index'] = dataset['user_id'].map(user_id_mapping)\n",
    "    dataset['asin_index'] = dataset['asin'].map(item_id_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ec735-c115-436a-bed8-a44e0fdcb7a5",
   "metadata": {},
   "source": [
    "In the following code block the data object is built that will be used in the surprise KNN and SVD models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41146a6e-2e50-4ba1-99aa-d4c03580d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test data for Surprise (required format)\n",
    "data_for_surprise = pd.concat([train_df, test_df])\n",
    "\n",
    "# Define the rating scale\n",
    "rating_scale = (df['rating'].min(), df['rating'].max())\n",
    "\n",
    "# Create a Reader object\n",
    "reader = Reader(rating_scale=rating_scale)\n",
    "\n",
    "# Load data into Surprise dataset\n",
    "data = Dataset.load_from_df(data_for_surprise[['user_id', 'asin', 'rating']], reader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc09343-c6f9-4933-8a7c-54de3c08ef48",
   "metadata": {},
   "source": [
    "### The Models\n",
    "Model order:\n",
    "1. KNN\n",
    "2. SVD\n",
    "3. ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1abefa-8b14-473f-9e0c-05f119ee37ed",
   "metadata": {},
   "source": [
    "## KNN - K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c27680-2e5b-4dec-8c6d-853c8cf8d209",
   "metadata": {},
   "source": [
    "In the similarity options for KNN I had to switch to item-based filtering because my computer did not have the memory run the user-based filtering version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fde6a0d-e6d5-439c-9470-e8c72987afba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x2a884ac6b90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build full training set (Surprise uses the entire dataset for training unless specified)\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "\n",
    "# Define similarity options\n",
    "sim_options = {\n",
    "    'name': 'cosine',  \n",
    "    'user_based': False  # Set to False for item-based filtering\n",
    "}\n",
    "\n",
    "# Initialize KNN model\n",
    "algo_knn = KNNBasic(sim_options=sim_options)\n",
    "\n",
    "# Train the model\n",
    "algo_knn.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e83dbf0-6678-41e2-ae59-6e3b32c4793c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9219\n"
     ]
    }
   ],
   "source": [
    "#Create testset for Surprise\n",
    "testset_surprise = list(zip(test_df['user_id'], test_df['asin'], test_df['rating']))\n",
    "\n",
    "# Get predictions\n",
    "predictions_knn = algo_knn.test(testset_surprise)\n",
    "\n",
    "rmse_knn = accuracy.rmse(predictions_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20664bc3-78a8-4cbd-9cb5-cbf158697bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended items for user A0009988MRFQ3TROTQPI using KNN: ['6300209830', 'B004L1DB8C', 'B00O2R6NX0', '6302970040', 'B011OCMQHW', 'B00079I09W', 'B00007JZO3', 'B000EOTV98', 'B00KNVF2SG', 'B0018LX9SA']\n"
     ]
    }
   ],
   "source": [
    "def recommend_knn(user_id, n=10):\n",
    "    # Get a list of all asins\n",
    "    all_items = set(data_for_surprise['asin'].unique())\n",
    "    # Get items the user has already interacted with\n",
    "    user_items = set(train_df[train_df['user_id'] == user_id]['asin'])\n",
    "    # Get items the user hasn't interacted with yet\n",
    "    items_to_predict = all_items - user_items\n",
    "    # Predict ratings for the tems\n",
    "    predictions = []\n",
    "    for item_id in items_to_predict:\n",
    "        pred = algo_knn.predict(str(user_id), str(item_id))\n",
    "        predictions.append((item_id, pred.est))\n",
    "    # Sort predictions by estimated rating\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    # Return top N asin\n",
    "    top_n_items = [item for item, rating in predictions[:n]]\n",
    "    return top_n_items\n",
    "\n",
    "user_id = train_df['user_id'].iloc[0]  # User the user in position 0\n",
    "recommended_items_knn = recommend_knn(user_id)\n",
    "print(f'Top recommended items for user {user_id} using KNN: {recommended_items_knn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be8d0ae6-cd59-4587-8fd5-e0888abdfd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Precision@10: 0.2037\n",
      "KNN Recall@10: 0.9094\n",
      "KNN F1 Score@10: 0.3329\n"
     ]
    }
   ],
   "source": [
    "# Get top N recommendations for KNN\n",
    "top_n_knn = get_top_n(predictions_knn, n=10)\n",
    "\n",
    "# Get actual relevant items for each user from test set\n",
    "actual_ratings = defaultdict(set)\n",
    "for _, row in test_df.iterrows():\n",
    "    if row['rating'] >= relevance_threshold:\n",
    "        actual_ratings[str(row['user_id'])].add(str(row['asin']))\n",
    "\n",
    "# Compute Precision@K and Recall@K for KNN\n",
    "precision_knn, recall_knn = compute_precision_recall_at_k(top_n_knn, actual_ratings, k=10, threshold=relevance_threshold)\n",
    "f1_score_knn = ((2*precision_knn * recall_knn)/ (recall_knn + precision_knn))\n",
    "print(f'KNN Precision@10: {precision_knn:.4f}')\n",
    "print(f'KNN Recall@10: {recall_knn:.4f}')\n",
    "print(f'KNN F1 Score@10: {f1_score_knn:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f7a12-9aee-41f9-927b-e6dd628a77ab",
   "metadata": {},
   "source": [
    "## SVD - Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d321c53-2e05-4618-ab73-2584413df0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2a918c43290>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize SVD model\n",
    "algo_svd = SVD(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "algo_svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b93bb9a2-b273-4627-b796-cedd74262779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6227\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for SVD\n",
    "predictions_svd = algo_svd.test(testset_surprise)\n",
    "\n",
    "# Evaluate RMSE\n",
    "rmse_svd = accuracy.rmse(predictions_svd)\n",
    "#print(f'SVD RMSE: {rmse_svd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0fe17f4-39ff-493f-a813-a55de083cd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended items for user A0009988MRFQ3TROTQPI using SVD: ['B00006FD8X', 'B00IJJBHW4', 'B0054JELS4', 'B00VU4YPR4', 'B00005QCV8', 'B0009VDJQ2', 'B00404ME0G', 'B001CMSDVS', 'B000P4ZL5K', 'B00CYQXE10']\n"
     ]
    }
   ],
   "source": [
    "# Function to recommend top N items for a user\n",
    "def recommend_svd(user_id, n=10):\n",
    "    # Get a list of all asins\n",
    "    all_items = set(data_for_surprise['asin'].unique())\n",
    "    # Get items the user has already interacted with\n",
    "    user_items = set(train_df[train_df['user_id'] == user_id]['asin'])\n",
    "    # Get items the user hasn't interacted with yet\n",
    "    items_to_predict = all_items - user_items\n",
    "    # Predict ratings for the items\n",
    "    predictions = []\n",
    "    for item_id in items_to_predict:\n",
    "        pred = algo_svd.predict(str(user_id), str(item_id))\n",
    "        predictions.append((item_id, pred.est))\n",
    "    # Sort predictions by estimated rating\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    # Return top N asins\n",
    "    top_n_items = [item for item, rating in predictions[:n]]\n",
    "    return top_n_items\n",
    "\n",
    "recommended_items_svd = recommend_svd(user_id)\n",
    "print(f'Top recommended items for user {user_id} using SVD: {recommended_items_svd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5da4a522-20d6-48a6-b411-58404597624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Precision@10: 0.2054\n",
      "SVD Recall@10: 0.9107\n",
      "SVD F1 Score@10: 0.3352\n"
     ]
    }
   ],
   "source": [
    "# Get top N recommendations for SVD\n",
    "top_n_svd = get_top_n(predictions_svd, n=10)\n",
    "\n",
    "# Get actual relevant items for each user from test set\n",
    "actual_ratings = defaultdict(set)\n",
    "for _, row in test_df.iterrows():\n",
    "    if row['rating'] >= relevance_threshold:\n",
    "        actual_ratings[str(row['user_id'])].add(str(row['asin']))\n",
    "\n",
    "# Compute Precision@K and Recall@K for SVD\n",
    "precision_svd, recall_svd = compute_precision_recall_at_k(top_n_svd, actual_ratings, k=10, threshold=relevance_threshold)\n",
    "f1_score_svd = ((2*precision_svd * recall_svd)/ (recall_svd + precision_svd))\n",
    "print(f'SVD Precision@10: {precision_svd:.4f}')\n",
    "print(f'SVD Recall@10: {recall_svd:.4f}')\n",
    "print(f'SVD F1 Score@10: {f1_score_svd:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1694f202-093b-4ae4-976a-6d93e5f6cf38",
   "metadata": {},
   "source": [
    "## PySpark ALS - Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cc6ac40-14b3-4c82-ad9d-ae30af346b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pyspark imports\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark import StorageLevel\n",
    "import findspark\n",
    "\n",
    "#Mean squared error from sklearn: : I learned later that there is a root_mean_squared_error now in sklearn but but it did not run for me and I did not want to update my code this far into the project\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Pyspark\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#Imports for environmental variables to be set so that PySpark can run\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "findspark.init() \n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Program Files\\Java\\jdk-22\"\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b1a32e0-a519-4425-978d-b93ea2984f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ad8a0b6-e7f9-47e7-8c38-bd7511659bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pandas DataFrame to Spark DataFrame\n",
    "train_spark_df = spark.createDataFrame(train_df[['user_index', 'asin_index', 'rating']])\n",
    "test_spark_df = spark.createDataFrame(test_df[['user_index', 'asin_index', 'rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a31508a-3ea6-43de-b8d1-a6901e3bc1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ALS model\n",
    "als = ALS(\n",
    "    maxIter=10,\n",
    "    regParam=0.1,\n",
    "    rank=50,\n",
    "    userCol='user_index',\n",
    "    itemCol='asin_index',\n",
    "    ratingCol='rating',\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=True,\n",
    "    implicitPrefs=False\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_als = als.fit(train_spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95cdab62-da7d-4165-a0c9-e6c5ebd1758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS RMSE: 0.9968222284871232\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "predictions_als = model_als.transform(test_spark_df)\n",
    "\n",
    "# Evaluate RMSE\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName='rmse',\n",
    "    labelCol='rating',\n",
    "    predictionCol='prediction'\n",
    ")\n",
    "rmse_als = evaluator.evaluate(predictions_als)\n",
    "print(f'ALS RMSE: {rmse_als}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fb6c53a-e59d-4eec-8327-f79cb685fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to Pandas DataFrame\n",
    "predictions_als_pandas = predictions_als.toPandas()\n",
    "\n",
    "# Merge with test_df to align user_id and asin\n",
    "als_results = test_df.merge(\n",
    "    predictions_als_pandas,\n",
    "    on=['user_index', 'asin_index'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Rename the prediction column to `als_pred`\n",
    "als_results = als_results.rename(columns={'prediction': 'als_pred'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27f21d81-9900-4b4e-8d5a-01c645258211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping from item_index to asin\n",
    "item_index_to_id = {v: k for k, v in item_id_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8543ddb-fff6-4c19-9b44-eaa35efabf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended items for user A0009988MRFQ3TROTQPI using ALS: ['1561270563', 'B005IFK660', 'B00012FX4A', 'B0064S0354', 'B000YI7LLY', 'B00006672Z', 'B000XJM7YA', 'B00009B1RV', 'B00005M2G1', 'B0012KK6R4']\n"
     ]
    }
   ],
   "source": [
    "# Function to recommend top N items for a user from the ALS model\n",
    "def recommend_als(user_id, n=10):\n",
    "    # Get user_index\n",
    "    if user_id not in user_id_mapping:\n",
    "        print(f'User {user_id} not found in training set.')\n",
    "        return []\n",
    "    user_index = user_id_mapping[user_id]\n",
    "    # Get items the user has already interacted with\n",
    "    user_items = set(train_df[train_df['user_id'] == user_id]['asin_index'])\n",
    "    # Get items the user hasn't interacted with yet\n",
    "    all_items = set(range(len(item_id_mapping)))\n",
    "    items_to_predict = list(all_items - user_items)\n",
    "    # Create a Spark DataFrame of user-asin pairs\n",
    "    from pyspark.sql.types import IntegerType\n",
    "    user_item_pairs = spark.createDataFrame(\n",
    "        [(user_index, item_idx) for item_idx in items_to_predict],\n",
    "        ['user_index', 'asin_index']\n",
    "    )\n",
    "    # Generate predictions\n",
    "    predictions = model_als.transform(user_item_pairs)\n",
    "    # Drop NaN values (if any)\n",
    "    predictions = predictions.na.drop()\n",
    "    # Get top N recommendations\n",
    "    predictions_df = predictions.toPandas()\n",
    "    top_n = predictions_df.sort_values('prediction', ascending=False).head(n)\n",
    "    # Map item_index back to asin\n",
    "    top_n['asin'] = top_n['asin_index'].map(item_index_to_id)\n",
    "    return top_n['asin'].tolist()\n",
    "\n",
    "# Example usage\n",
    "recommended_items_als = recommend_als(user_id)\n",
    "print(f'Top recommended items for user {user_id} using ALS: {recommended_items_als}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09393edc-ac9c-4fe6-a28b-91e269b4b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top N recommendations for each user using ALS\n",
    "user_recs = model_als.recommendForAllUsers(10)\n",
    "user_recs_pandas = user_recs.toPandas()\n",
    "\n",
    "# Map recommendations to user_ids\n",
    "top_n_als = defaultdict(list)\n",
    "for index, row in user_recs_pandas.iterrows():\n",
    "    user_index = row['user_index']\n",
    "    user_id = user_index_to_id[user_index]\n",
    "    recommendations = row['recommendations']\n",
    "    for rec in recommendations:\n",
    "        item_index = rec['asin_index']\n",
    "        est = rec['rating']\n",
    "        item_id = item_index_to_id[item_index]\n",
    "        top_n_als[user_id].append((item_id, est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c66973e0-d518-41ee-9de0-c85809c1fbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Precision@10: 0.0013\n",
      "ALS Recall@10: 0.0073\n",
      "ALS F1 Score@10: 0.002258\n"
     ]
    }
   ],
   "source": [
    "# Compute Precision@K and Recall@K for ALS\n",
    "precision_als, recall_als = compute_precision_recall_at_k(top_n_als, actual_ratings, k=10, threshold=relevance_threshold)\n",
    "f1_score_als = ((2*precision_als * recall_als)/ (recall_als + precision_als))\n",
    "print(f'ALS Precision@10: {precision_als:.4f}')\n",
    "print(f'ALS Recall@10: {recall_als:.4f}')\n",
    "print(f'ALS F1 Score@10: {f1_score_als:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9712a9-3c04-4533-978c-549acf126cab",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e3244-c0fe-4dfc-83d8-4478174b04bf",
   "metadata": {},
   "source": [
    "After completing the previous models I wanted to see how an ensemble model would perform. I had initially planned to use all three models but after seeing how poorly ALS performed I opted to only use KNN and SVD in the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e228ef57-6a14-4b58-9a20-250ec6da7574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert KNN predictions to DataFrame\n",
    "knn_pred_df = pd.DataFrame([(pred.uid, pred.iid, pred.est) for pred in predictions_knn],\n",
    "                           columns=['user_id', 'asin', 'knn_pred'])\n",
    "\n",
    "# Merge with test_df\n",
    "ensemble_df = test_df.merge(knn_pred_df, on=['user_id', 'asin'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3de2ee2-793d-4e48-b729-23d3c102d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SVD predictions to DataFrame\n",
    "svd_pred_df = pd.DataFrame([(pred.uid, pred.iid, pred.est) for pred in predictions_svd],\n",
    "                           columns=['user_id', 'asin', 'svd_pred'])\n",
    "\n",
    "# Merge with ensemble_df\n",
    "ensemble_df = ensemble_df.merge(svd_pred_df, on=['user_id', 'asin'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61f9704e-1b3e-4b9d-aef2-184fcd9383f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_17144\\271969875.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ensemble_df['knn_pred'].fillna(mean_rating, inplace=True)\n",
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_17144\\271969875.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ensemble_df['svd_pred'].fillna(mean_rating, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill any missing predictions with the mean rating\n",
    "mean_rating = train_df['rating'].mean()\n",
    "ensemble_df['knn_pred'].fillna(mean_rating, inplace=True)\n",
    "ensemble_df['svd_pred'].fillna(mean_rating, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66d0aaa9-feae-45f7-8c2f-e378d67349e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "KNN Weight: 0.4031\n",
      "SVD Weight: 0.5969\n"
     ]
    }
   ],
   "source": [
    "#Weight the models by the inverse of their RMSE\n",
    "weight_svd = 1 / rmse_svd\n",
    "weight_knn = 1 / rmse_knn\n",
    "\n",
    "total_weight = weight_svd + weight_knn\n",
    "\n",
    "# Generate the ratio each model's weight has on the total weight\n",
    "weight_svd /= total_weight\n",
    "weight_knn /= total_weight\n",
    "\n",
    "# The weights\n",
    "print(f'Weights:')\n",
    "print(f'KNN Weight: {weight_knn:.4f}')\n",
    "print(f'SVD Weight: {weight_svd:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f849b23b-aa42-4949-a5d0-ea9092cbbc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply weights to ensemble predictions\n",
    "ensemble_df['ensemble_pred'] = (\n",
    "    ensemble_df['knn_pred'] * weight_knn +\n",
    "    ensemble_df['svd_pred'] * weight_svd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a276938-efd6-42c8-b61c-60d5376b5d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble RMSE: 0.7148613431740194\n"
     ]
    }
   ],
   "source": [
    "# Actual ratings\n",
    "true_ratings = ensemble_df['rating'].values\n",
    "\n",
    "# Ensemble predictions\n",
    "ensemble_predictions = ensemble_df['ensemble_pred'].values\n",
    "\n",
    "# Compute RMSE\n",
    "ensemble_rmse = mean_squared_error(true_ratings, ensemble_predictions, squared=False)\n",
    "print(f'Ensemble RMSE: {ensemble_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e4240-d078-4840-9194-55b14a3f2c79",
   "metadata": {},
   "source": [
    "The initial ensemble recommendation function tooks hours to run. After doing research and learning how to batch the predictinos it became significantly faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c012ec97-1089-44e4-b470-2363edf324a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended items for user A3T1AUE5RSBOS6 using the Ensemble model: ['B001JTRKHW', '6302484286', 'B00D3PYS6Q', 'B00005T30I', 'B000096IBI', 'B000EHQU12', '837255773X', 'B011SDC12M', 'B0047UJBMC', 'B000069HXD']\n"
     ]
    }
   ],
   "source": [
    "# Function to recommend top N items for a user using the ensemble\n",
    "def recommend_ensemble_batch(user_id, n=10):\n",
    "    # Get items the user hasn't interacted with\n",
    "    user_items = set(train_df[train_df['user_id'] == user_id]['asin'])\n",
    "    all_items = set(data_for_surprise['asin'].unique())\n",
    "    items_to_predict = list(all_items - user_items)\n",
    "    items_to_predict_str = [str(item_id) for item_id in items_to_predict]\n",
    "    user_id_str = str(user_id)\n",
    "\n",
    "    # Prepare user-item pairs with a placeholder rating (e.g., 0)\n",
    "    user_item_pairs = [(user_id_str, item_id_str, 0) for item_id_str in items_to_predict_str]\n",
    "\n",
    "    # Batch predictions with KNN\n",
    "    predictions_knn = algo_knn.test(user_item_pairs)\n",
    "    knn_preds = {pred.iid: pred.est for pred in predictions_knn}\n",
    "\n",
    "    # Batch predictions with SVD\n",
    "    predictions_svd = algo_svd.test(user_item_pairs)\n",
    "    svd_preds = {pred.iid: pred.est for pred in predictions_svd}\n",
    "\n",
    "    # Combine predictions\n",
    "    combined_predictions = []\n",
    "    for item_id_str in items_to_predict_str:\n",
    "        preds = []\n",
    "        if item_id_str in knn_preds:\n",
    "            preds.append((knn_preds[item_id_str], weight_knn))\n",
    "        if item_id_str in svd_preds:\n",
    "            preds.append((svd_preds[item_id_str], weight_svd))\n",
    "        if preds:\n",
    "            # Weighted average of predictions\n",
    "            weighted_sum = sum(pred * weight for pred, weight in preds)\n",
    "            weight_sum = sum(weight for _, weight in preds)\n",
    "            combined_pred = weighted_sum / weight_sum\n",
    "            combined_predictions.append((item_id_str, combined_pred))\n",
    "\n",
    "    # Sort predictions by estimated rating\n",
    "    combined_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return top N item_ids\n",
    "    top_n_items = [item for item, rating in combined_predictions[:n]]\n",
    "    return top_n_items\n",
    "\n",
    "\n",
    "recommended_items_ensemble = recommend_ensemble_batch(user_id)\n",
    "print(f'Top recommended items for user {user_id} using the Ensemble model: {recommended_items_ensemble}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5ca8784-b23f-4af9-9fb5-b01d145b4e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Precision@10: 0.2054\n",
      "Ensemble Recall@10: 0.9107\n",
      "Ensemble F1 Score@10: 0.3352\n"
     ]
    }
   ],
   "source": [
    "# Get top N recommendations for Ensemble\n",
    "top_n_ensemble = defaultdict(list)\n",
    "ensemble_predictions = []\n",
    "\n",
    "for index, row in ensemble_df.iterrows():\n",
    "    user_id = str(row['user_id'])\n",
    "    item_id = str(row['asin'])\n",
    "    est = row['ensemble_pred']\n",
    "    ensemble_predictions.append((user_id, item_id, est))\n",
    "\n",
    "# Map predictions to each user\n",
    "for user_id, item_id, est in ensemble_predictions:\n",
    "    top_n_ensemble[user_id].append((item_id, est))\n",
    "\n",
    "# Sort and get top N\n",
    "for user_id, user_ratings in top_n_ensemble.items():\n",
    "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_n_ensemble[user_id] = user_ratings[:10]\n",
    "\n",
    "# Compute Precision@K and Recall@K for Ensemble\n",
    "precision_ensemble, recall_ensemble = compute_precision_recall_at_k(top_n_ensemble, actual_ratings, k=10, threshold=relevance_threshold)\n",
    "f1_score_ensemble = ((2*precision_ensemble * recall_ensemble)/ (recall_ensemble + precision_ensemble))\n",
    "print(f'Ensemble Precision@10: {precision_ensemble:.4f}')\n",
    "print(f'Ensemble Recall@10: {recall_ensemble:.4f}')\n",
    "print(f'Ensemble F1 Score@10: {f1_score_ensemble:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588837a7-c39e-47cf-85bc-a42395ccc750",
   "metadata": {},
   "source": [
    "### Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "871655cf-c69b-410b-87c9-e190ca1b76a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Summary:\n",
      "KNN RMSE: 0.9219278522943515\n",
      "SVD RMSE: 0.6226858510489055\n",
      "ALS RMSE: 0.9968222284871232\n",
      "Ensemble RMSE: 0.7148613431740194\n",
      "\n",
      "Recommendation Quality Metrics:\n",
      "KNN Precision@10: 0.2037, Recall@10: 0.9094, F1Score@10: 0.3329\n",
      "SVD Precision@10: 0.2054, Recall@10: 0.9107, F1Score@10: 0.3352\n",
      "ALS Precision@10: 0.0013, Recall@10: 0.0073, F1Score@10: 0.002258\n",
      "Ensemble Precision@10: 0.2054, Recall@10: 0.9107, F1Score@10: 0.3352\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(f\"KNN RMSE: {rmse_knn}\")\n",
    "print(f\"SVD RMSE: {rmse_svd}\")\n",
    "print(f\"ALS RMSE: {rmse_als}\")\n",
    "print(f\"Ensemble RMSE: {ensemble_rmse}\")\n",
    "\n",
    "print(\"\\nRecommendation Quality Metrics:\")\n",
    "print(f'KNN Precision@10: {precision_knn:.4f}, Recall@10: {recall_knn:.4f}, F1Score@10: {f1_score_knn:.4}')\n",
    "print(f'SVD Precision@10: {precision_svd:.4f}, Recall@10: {recall_svd:.4f}, F1Score@10: {f1_score_svd:.4}')\n",
    "print(f'ALS Precision@10: {precision_als:.4f}, Recall@10: {recall_als:.4f}, F1Score@10: {f1_score_als:.4}')\n",
    "print(f'Ensemble Precision@10: {precision_ensemble:.4f}, Recall@10: {recall_ensemble:.4f}, F1Score@10: {f1_score_ensemble:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2f027fd-b27b-4f3b-9649-def3590e8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of test_df with actual ratings\n",
    "comparison_df = test_df[['user_id', 'asin', 'rating']].rename(columns={'rating': 'actual_rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1c9a910-d1df-4b5a-b837-5cea48114273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging all the predictions into one df so that the predictions can be compared side by side\n",
    "comparison_df = comparison_df.merge(knn_pred_df[['user_id', 'asin', 'knn_pred']], on=['user_id', 'asin'], how='left')\n",
    "comparison_df = comparison_df.merge(svd_pred_df[['user_id', 'asin', 'svd_pred']], on=['user_id', 'asin'], how='left')\n",
    "comparison_df = comparison_df.merge(als_results[['user_id', 'asin', 'als_pred']], on=['user_id', 'asin'], how='left')\n",
    "comparison_df = comparison_df.merge(ensemble_df[['user_id', 'asin', 'ensemble_pred']], on=['user_id', 'asin'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c808738-10f7-4052-b367-b3388f269a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>asin</th>\n",
       "      <th>actual_rating</th>\n",
       "      <th>knn_pred</th>\n",
       "      <th>svd_pred</th>\n",
       "      <th>als_pred</th>\n",
       "      <th>ensemble_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0009988MRFQ3TROTQPI</td>\n",
       "      <td>B000BMSUBI</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.199226</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0009988MRFQ3TROTQPI</td>\n",
       "      <td>B009INAMA8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.707128</td>\n",
       "      <td>4.471426</td>\n",
       "      <td>4.825195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00311542N70JGNHUZPI</td>\n",
       "      <td>B0014Z3OQW</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.783487</td>\n",
       "      <td>4.855718</td>\n",
       "      <td>4.870771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0040548BPHKXMHH3NTI</td>\n",
       "      <td>B00X7SIALI</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.108956</td>\n",
       "      <td>4.188138</td>\n",
       "      <td>4.399876</td>\n",
       "      <td>4.156217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0040548BPHKXMHH3NTI</td>\n",
       "      <td>B0092QDMQ2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.108956</td>\n",
       "      <td>4.184728</td>\n",
       "      <td>4.376638</td>\n",
       "      <td>4.154182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199045</th>\n",
       "      <td>A2AZIQJGBLU7WN</td>\n",
       "      <td>B01HGRJUGE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>3.331971</td>\n",
       "      <td>3.061921</td>\n",
       "      <td>3.349317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199046</th>\n",
       "      <td>A2ZNT49VN00YA3</td>\n",
       "      <td>B01HH20HHE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.113785</td>\n",
       "      <td>3.878240</td>\n",
       "      <td>3.878754</td>\n",
       "      <td>3.973196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199047</th>\n",
       "      <td>A1GPDRU8VBWN3E</td>\n",
       "      <td>B01HH20HHE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.425000</td>\n",
       "      <td>4.733786</td>\n",
       "      <td>4.710001</td>\n",
       "      <td>4.609304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199048</th>\n",
       "      <td>A2NDDQLMA8XAUZ</td>\n",
       "      <td>B01HH20HHE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.714126</td>\n",
       "      <td>4.783737</td>\n",
       "      <td>4.829371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199049</th>\n",
       "      <td>A1TO2Q0I8LNSAR</td>\n",
       "      <td>B01HH20HHE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.499843</td>\n",
       "      <td>2.871479</td>\n",
       "      <td>2.310536</td>\n",
       "      <td>3.124794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199050 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_id        asin  actual_rating  knn_pred  svd_pred  \\\n",
       "0        A0009988MRFQ3TROTQPI  B000BMSUBI            5.0  5.000000  5.000000   \n",
       "1        A0009988MRFQ3TROTQPI  B009INAMA8            5.0  5.000000  4.707128   \n",
       "2        A00311542N70JGNHUZPI  B0014Z3OQW            5.0  5.000000  4.783487   \n",
       "3        A0040548BPHKXMHH3NTI  B00X7SIALI            4.0  4.108956  4.188138   \n",
       "4        A0040548BPHKXMHH3NTI  B0092QDMQ2            4.0  4.108956  4.184728   \n",
       "...                       ...         ...            ...       ...       ...   \n",
       "1199045        A2AZIQJGBLU7WN  B01HGRJUGE            3.0  3.375000  3.331971   \n",
       "1199046        A2ZNT49VN00YA3  B01HH20HHE            4.0  4.113785  3.878240   \n",
       "1199047        A1GPDRU8VBWN3E  B01HH20HHE            5.0  4.425000  4.733786   \n",
       "1199048        A2NDDQLMA8XAUZ  B01HH20HHE            5.0  5.000000  4.714126   \n",
       "1199049        A1TO2Q0I8LNSAR  B01HH20HHE            2.0  3.499843  2.871479   \n",
       "\n",
       "         als_pred  ensemble_pred  \n",
       "0        4.199226       5.000000  \n",
       "1        4.471426       4.825195  \n",
       "2        4.855718       4.870771  \n",
       "3        4.399876       4.156217  \n",
       "4        4.376638       4.154182  \n",
       "...           ...            ...  \n",
       "1199045  3.061921       3.349317  \n",
       "1199046  3.878754       3.973196  \n",
       "1199047  4.710001       4.609304  \n",
       "1199048  4.783737       4.829371  \n",
       "1199049  2.310536       3.124794  \n",
       "\n",
       "[1199050 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e2ad7c6-b136-4220-bc48-c41bda72aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopping the PySpark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
